{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "after-producer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path; import os\n",
    "cwd_path = Path.cwd(); set_path = str(cwd_path.parent); os.chdir(set_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "african-suspension",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow_addons.layers import WeightNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "labeled-delaware",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cloudy-karen",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_probability import layers as tfp_layers\n",
    "WeightNormalization = tfp_layers.weight_norm.WeightNorm\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sorted-teddy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Flatten, Layer, Reshape, Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "corresponding-salvation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Inverse_Autoregressive_Flow.AutoregressiveNN.Input_layer import Autoregressive_input_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "considered-finland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 5.0343215e-03 -1.3214946e-02  5.3657074e-02 -7.5748801e-02\n",
      "  -1.6861320e-02 -1.0000000e+00  9.1054688e+01]], shape=(1, 7), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "input_layer = Autoregressive_input_layer(3, 4, units=7)\n",
    "latent_z = np.array([1, 1000, 1005], dtype=\"float32\")[np.newaxis, :]\n",
    "h = np.ones((4,), dtype=\"float32\")[np.newaxis, :]\n",
    "print(input_layer([latent_z, h]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dominant-obligation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gives an error\n",
    "\"\"\"\n",
    "input_layer = WeightNormalization(Autoregressive_input_layer(3, 4, units=7))\n",
    "latent_z = np.array([1, 1000, 1005], dtype=\"float32\")[np.newaxis, :]\n",
    "h = np.ones((4,), dtype=\"float32\")[np.newaxis, :]\n",
    "print(input_layer([latent_z, h]))\n",
    "\"\"\"\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "juvenile-playlist",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(tf.keras.layers.Layer):\n",
    "    def __init__(self, units=32):\n",
    "        super(Linear, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            shape=(input_shape[-1], self.units),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.biases = self.add_weight(\n",
    "            shape=(self.units,), initializer=\"random_normal\", trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.kernel) + self.biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dated-assistant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
       "array([[ -82.502045 ,    2.1578898,   -4.050124 ,  -26.298466 ,\n",
       "          29.399246 ,  170.78648  ,  -92.37528  ,  -38.358284 ,\n",
       "           8.093197 ,  -82.31457  ,   48.380844 ,  -29.157846 ,\n",
       "          29.094372 ,  -22.753048 , -118.95863  ,   62.945435 ,\n",
       "          -7.698193 ,  -36.90656  ,  -16.66807  ,  -71.744    ,\n",
       "          15.480982 ,  -31.885298 ,   -5.15213  ,   82.992584 ,\n",
       "          -5.1770186, -174.69043  ,   95.22082  ,  105.72761  ,\n",
       "          12.130077 ,   -5.6468024,  -36.42094  ,   82.22339  ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Linear()(latent_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "respected-liver",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-2d2132974bef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlay\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWeightNormalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatent_z\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\envs\\VAE\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1006\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1007\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1008\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n",
      "\u001b[1;32m~\\miniconda3\\envs\\VAE\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2708\u001b[0m         \u001b[1;31m# operations.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2709\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2710\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint:disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2711\u001b[0m       \u001b[1;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2712\u001b[0m       \u001b[1;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\VAE\\lib\\site-packages\\tensorflow_probability\\python\\layers\\weight_norm.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    174\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialized\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWeightNorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\VAE\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\wrappers.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-3956a9d6fc14>\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         self.kernel = self.add_weight(\n\u001b[1;32m----> 8\u001b[1;33m             \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"random_normal\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "lay = WeightNormalization(Linear())\n",
    "lay(latent_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-pipeline",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "noticed-prague",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoregressive_input_layer(Layer):\n",
    "    \"\"\"\n",
    "    Autoregressive inputs refer to inputs were we need to maintain autoregressive structure as in MADE paper\n",
    "    Specifically here the dimension of the autoregressive_input_dim is the latent representation dimension\n",
    "    non_autoregressive inputs are fully connected (this represents h in IAF paper)\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, autoregressive_input_dim, non_autoregressive_input_dim, units=64):\n",
    "        super(Autoregressive_input_layer, self).__init__()\n",
    "        assert units >= autoregressive_input_dim\n",
    "        self.autoregressive_input_dim = autoregressive_input_dim\n",
    "        self.non_autoregressive_input_dim = non_autoregressive_input_dim\n",
    "        self.units = units\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        autoregressive_input_dim = self.autoregressive_input_dim #input_shape[0][-1]\n",
    "        non_autoregressive_input_dim = self.non_autoregressive_input_dim #input_shape[1][-1]\n",
    "        self.kernel = self.add_weight(\n",
    "        shape=(autoregressive_input_dim, self.units),\n",
    "        initializer=\"random_normal\",\n",
    "        trainable=True,\n",
    "        )\n",
    "        # masking\n",
    "        self.autoregressive_weights_mask = np.zeros((autoregressive_input_dim, self.units))\n",
    "        nodes_per_latent_representation_dim = self.units / autoregressive_input_dim\n",
    "        for i in range(autoregressive_input_dim):\n",
    "            for j in range(self.units):\n",
    "                units_corresponding_max_autoregressive_input_index = j//nodes_per_latent_representation_dim\n",
    "                if units_corresponding_max_autoregressive_input_index > i:\n",
    "                    self.autoregressive_weights_mask[i, j] = 1\n",
    "        self.autoregressive_weights_mask = tf.convert_to_tensor(self.autoregressive_weights_mask, dtype=\"float32\")\n",
    "        \n",
    "        self.non_autoregressive_weights = self.add_weight(shape=(non_autoregressive_input_dim, self.units),\n",
    "                                                                 initializer=\"random_normal\",\n",
    "                                                                 trainable=True, dtype=\"float32\")\n",
    "        \n",
    "        # biases\n",
    "        self.biases = self.add_weight(\n",
    "            shape=(self.units,), initializer=\"random_normal\", trainable=True)\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        h_non_autoregressive = inputs[:, self.autoregressive_input_dim:]\n",
    "        z_autoregressive = inputs[:, :self.autoregressive_input_dim]\n",
    "        x = tf.matmul(z_autoregressive, self.autoregressive_weights*self.autoregressive_weights_mask) + \\\n",
    "            tf.matmul(h_non_autoregressive, self.non_autoregressive_weights) \\\n",
    "            + self.biases\n",
    "        #return tf.nn.relu(x)\n",
    "        return tf.nn.elu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "japanese-korean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 9.8826647e-02  5.2792039e-03  2.7916100e-02 -6.9247961e-02\n",
      "  -1.2243986e-01 -1.0000000e+00  5.8842025e+00]], shape=(1, 7), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "input_layer = Autoregressive_input_layer(3, 4, units=7)\n",
    "latent_z = np.array([1, 1000, 1005], dtype=\"float32\")[np.newaxis, :]\n",
    "h = np.ones((4,), dtype=\"float32\")[np.newaxis, :]\n",
    "concat = tf.keras.layers.Concatenate()([latent_z, h])\n",
    "print(input_layer(concat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "alien-legislature",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`WeightNorm` must wrap a layer that contains a `kernel` for weights",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-88db2351c9a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"float32\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mconcat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlatent_z\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\envs\\VAE\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1006\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1007\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1008\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n",
      "\u001b[1;32m~\\miniconda3\\envs\\VAE\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2708\u001b[0m         \u001b[1;31m# operations.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2709\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2710\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint:disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2711\u001b[0m       \u001b[1;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2712\u001b[0m       \u001b[1;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\VAE\\lib\\site-packages\\tensorflow_probability\\python\\layers\\weight_norm.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'kernel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m         raise ValueError('`WeightNorm` must wrap a layer that'\n\u001b[0m\u001b[0;32m    152\u001b[0m                          ' contains a `kernel` for weights')\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: `WeightNorm` must wrap a layer that contains a `kernel` for weights"
     ]
    }
   ],
   "source": [
    "input_layer = WeightNormalization(Autoregressive_input_layer(3, 4, units=7))\n",
    "latent_z = np.array([1, 1000, 1005], dtype=\"float32\")[np.newaxis, :]\n",
    "h = np.ones((4,), dtype=\"float32\")[np.newaxis, :]\n",
    "concat = tf.keras.layers.Concatenate()([latent_z, h])\n",
    "print(input_layer(concat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seasonal-anniversary",
   "metadata": {},
   "source": [
    "# Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-vinyl",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = WeightNormalization(tf.keras.layers.Dense(10, activation=\"elu\", name=\"layer1\"),\n",
    "                                            data_init=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-packing",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "center-newman",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs = np.array([[1.0,2.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-future",
   "metadata": {},
   "outputs": [],
   "source": [
    "x(test_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-efficiency",
   "metadata": {},
   "source": [
    "# Overwrite Dense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revolutionary-plymouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-luxembourg",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dense(1).get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-machine",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(tf.keras.layers.Dense):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(Dense, self).__init__(*args, **kwargs)\n",
    "        self.dummy = 1e6\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return (tf.matmul(inputs, self.kernel) + self.bias) * self.dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-parallel",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dense(3).get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-speaking",
   "metadata": {},
   "outputs": [],
   "source": [
    "overwritten = WeightNormalization(Dense(3),\n",
    "                                            data_init=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-analyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "overwritten(test_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-plant",
   "metadata": {},
   "source": [
    "# Custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-roberts",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_initialiser = tf.random_normal_initializer()\n",
    "self.autoregressive_weights = \\\n",
    "    tf.Variable(initial_value=weight_initialiser(shape=(autoregressive_input_dim, units),\n",
    "                dtype=\"float32\"), trainable=True)\n",
    "self.autoregressive_weights_mask = np.zeros((autoregressive_input_dim, units))\n",
    "# TODO can do this without a lengthy loop\n",
    "\n",
    "nodes_per_latent_representation_dim = units / autoregressive_input_dim\n",
    "for i in range(autoregressive_input_dim):\n",
    "    for j in range(units):\n",
    "        units_corresponding_max_autoregressive_input_index = j//nodes_per_latent_representation_dim\n",
    "        if units_corresponding_max_autoregressive_input_index > i:\n",
    "            self.autoregressive_weights_mask[i, j] = 1\n",
    "self.autoregressive_weights_mask = tf.convert_to_tensor(self.autoregressive_weights_mask, dtype=\"float32\")\n",
    "#self.L_mask = np.zeros((autoregressive_input_dim, units)).astype(\"float32\")\n",
    "#self.L_mask = np.tril(self.L_mask, k=-1) # we can do this if units=autoregressive_input_dim\n",
    "\n",
    "self.non_autoregressive_weights = \\\n",
    "    tf.Variable(initial_value=weight_initialiser(shape=(non_autoregressive_input_dim, units),\n",
    "                                                 dtype=\"float32\"), trainable=True)\n",
    "self.biases = tf.Variable(initial_value=tf.zeros_initializer()(shape=(units, ), dtype=\"float32\"),\n",
    "                          trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-handbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoregressive_input_layer(tf.keras.layers.Dense):\n",
    "    \"\"\"\n",
    "    Autoregressive inputs refer to inputs were we need to maintain autoregressive structure as in MADE paper\n",
    "    Specifically here the dimension of the autoregressive_input_dim is the latent representation dimension\n",
    "    non_autoregressive inputs are fully connected (this represents h in IAF paper)\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, autoregressive_input_dim, non_autoregressive_input_dim, units=64):\n",
    "        super(Autoregressive_input_layer, self).__init__()\n",
    "        assert units >= autoregressive_input_dim\n",
    "        self.autoregressive_input_dim = autoregressive_input_dim\n",
    "        self.non_autoregressive_input_dim = non_autoregressive_input_dim\n",
    "        self.units = units\n",
    "    \n",
    "    def build(input_shape):\n",
    "                self.kernel = self.add_weight(\n",
    "            shape=(input_shape[-1], self.units),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.bias = self.add_weight(\n",
    "            shape=(self.units,), initializer=\"random_normal\", trainable=True\n",
    "        )\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_autoregressive, h_non_autoregressive = inputs\n",
    "        x = tf.matmul(z_autoregressive, self.autoregressive_weights*self.autoregressive_weights_mask) + \\\n",
    "            tf.matmul(h_non_autoregressive, self.non_autoregressive_weights) \\\n",
    "            + self.biases\n",
    "        #return tf.nn.relu(x)\n",
    "        return tf.nn.elu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-buffer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liquid-briefs",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(tf.keras.layers.Layer):\n",
    "    def __init__(self, units=32, **kwargs):\n",
    "        super(Dense, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.dogfish  = 2\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(\n",
    "            shape=(input_shape[-1], self.units),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.bias = self.add_weight(\n",
    "            shape=(self.units,), initializer=\"random_normal\", trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.bias\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Dense, self).get_config()\n",
    "        config.update({\"units\": self.units})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-despite",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = WeightNormalization(Dense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-yorkshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "x(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "reserved-satisfaction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-clock",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Flatten, Layer, Reshape, Concatenate\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class Autoregressive_input_layer(Layer):\n",
    "    \"\"\"\n",
    "    Autoregressive inputs refer to inputs were we need to maintain autoregressive structure as in MADE paper\n",
    "    Specifically here the dimension of the autoregressive_input_dim is the latent representation dimension\n",
    "    non_autoregressive inputs are fully connected (this represents h in IAF paper)\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, autoregressive_input_dim, non_autoregressive_input_dim, units=64):\n",
    "        super(Autoregressive_input_layer, self).__init__()\n",
    "        assert units >= autoregressive_input_dim\n",
    "        weight_initialiser = tf.random_normal_initializer()\n",
    "        self.autoregressive_weights = \\\n",
    "            tf.Variable(initial_value=weight_initialiser(shape=(autoregressive_input_dim, units),\n",
    "                        dtype=\"float32\"), trainable=True)\n",
    "        self.autoregressive_weights_mask = np.zeros((autoregressive_input_dim, units))\n",
    "        nodes_per_latent_representation_dim = units / autoregressive_input_dim\n",
    "        for i in range(autoregressive_input_dim):\n",
    "            for j in range(units):\n",
    "                units_corresponding_max_autoregressive_input_index = j//nodes_per_latent_representation_dim\n",
    "                if units_corresponding_max_autoregressive_input_index > i:\n",
    "                    self.autoregressive_weights_mask[i, j] = 1\n",
    "        self.autoregressive_weights_mask = tf.convert_to_tensor(self.autoregressive_weights_mask, dtype=\"float32\")\n",
    "\n",
    "\n",
    "        self.non_autoregressive_weights = \\\n",
    "            tf.Variable(initial_value=weight_initialiser(shape=(non_autoregressive_input_dim, units),\n",
    "                                                         dtype=\"float32\"), trainable=True)\n",
    "        self.biases = tf.Variable(initial_value=tf.zeros_initializer()(shape=(units, ), dtype=\"float32\"),\n",
    "                                  trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_autoregressive, h_non_autoregressive = inputs\n",
    "        x = tf.matmul(z_autoregressive, self.autoregressive_weights*self.autoregressive_weights_mask) + \\\n",
    "            tf.matmul(h_non_autoregressive, self.non_autoregressive_weights) \\\n",
    "            + self.biases\n",
    "        #return tf.nn.relu(x)\n",
    "        return tf.nn.elu(x)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # simple example with latent dim of 2\n",
    "    input_layer = Autoregressive_input_layer(3, 4, units=7)\n",
    "    print(input_layer.autoregressive_weights_mask)\n",
    "    latent_z = np.array([1, 1000, 1005], dtype=\"float32\")[np.newaxis, :]\n",
    "    h = np.ones((4,), dtype=\"float32\")[np.newaxis, :]\n",
    "    print(input_layer([latent_z, h]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
